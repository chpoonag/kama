{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "# !pip install ta\n",
    "import ta\n",
    "# from mpl_finance import candlestick2_ohlc\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.contrib.telegram import tqdm, trange\n",
    "from scipy import optimize\n",
    "import winsound\n",
    "\n",
    "# # for using GPU\n",
    "# from numba import jit, cuda\n",
    "\n",
    "# to measure exec time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "\n",
    "# import json\n",
    "# import datetime as dt\n",
    "\n",
    "def save_as_json(inp_dict, output_folder, indent = 4, output_filename_prefix = 'output'):\n",
    "    now = dt.datetime.now()\n",
    "    ret = [now.month, now.day, now.hour, now.minute]\n",
    "    ret = ['0' + str(i) if len(str(i)) == 1 else i for i in ret]\n",
    "    now_str = \"{}{}{}-{}{}-{}\".format(now.year, ret[0], ret[1], ret[2], ret[3], now.second)\n",
    "    output_filename = f'{output_filename_prefix}_{now_str}.json'\n",
    "    output_path = f'{output_folder}\\\\{output_filename}'\n",
    "    \n",
    "    out_file = open(output_path, \"w\")\n",
    "    json.dump(inp_dict, out_file, indent = indent)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime as dt\n",
    "# import pandas as pd\n",
    "\n",
    "def save_as_csv(input_df, output_folder, output_filename_prefix = 'output'):\n",
    "#     output_folder = r'C:\\Users\\priva\\OneDrive - HKUST Connect\\Stock\\Data\\temp outputs'\n",
    "    now = dt.datetime.now()\n",
    "    ret = [now.month, now.day, now.hour, now.minute]\n",
    "    ret = ['0' + str(i) if len(str(i)) == 1 else i for i in ret]\n",
    "    now_str = \"{}{}{}-{}{}-{}\".format(now.year, ret[0], ret[1], ret[2], ret[3], now.second)\n",
    "    output_filename = f'{output_filename_prefix}_{now_str}.csv'\n",
    "    \n",
    "    output_link = f'{output_folder}\\\\{output_filename}'\n",
    "    input_df.to_csv(output_link)\n",
    "    print(f\"Output file is saved to \\n{output_folder}\\nFilename: {output_filename}\")\n",
    "    return output_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_telegram(message, token, chat_id):\n",
    "    import requests\n",
    "    apiURL = f'https://api.telegram.org/bot{token}/sendMessage'\n",
    "\n",
    "    try:\n",
    "        response = requests.post(apiURL, json={'chat_id': chat_id, 'text': message})\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Download from Yahoo Finance\n",
    "# ticker = \"0388.HK\"\n",
    "# start_date = int(dt.datetime(2005,1,1).timestamp())\n",
    "# end_date = int(dt.datetime(2015,1,1).timestamp())\n",
    "# interval = \"1d\"\n",
    "\n",
    "# df = pd.read_csv(\"https://query1.finance.yahoo.com/v7/finance/download/{}?period1={}&period2={}&interval={}&events=history&includeAdjustedClose=true\".\n",
    "#                        format(ticker, start_date, end_date, interval))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Planet Edu\\OneDrive\\Tutor 導師\\George\\temp\\asset\\^GSPC_1d_19280103_20221027.csv')\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Adj Close with Close\n",
    "# drop the Adj Close column\n",
    "df['Close'] = df['Adj Close']\n",
    "df = df.drop(columns = ['Adj Close'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Close_ln'] = np.log(df['Close'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Version 3\n",
    "\n",
    "# @jit(target_backend='cuda') \n",
    "def backtest(df, long_rules, short_rules, long_only = True, \\\n",
    "             initial_capital=100000, commission_percent=0.5, risk_free_rate = 5, \\\n",
    "             buy_next_day=True, date='Date', buy_at = 'Close',\\\n",
    "             signals='Signals', shares='Shares', cash='Cash', stock='Stock', equity='Equity', \n",
    "             action_completed = \"Action Completed\"):\n",
    "    \n",
    "    df = df.copy()\n",
    "    df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "    # Assume no short selling allowed\n",
    "    # ie sell holing stocks whenever a short signal is triggered\n",
    "    \n",
    "    # Check for any conflicts between long_rules and short_rules\n",
    "    for i in range(len(long_rules)):\n",
    "        # Cannot long/short at the same time\n",
    "        if abs(long_rules[i])>0 and abs(short_rules[i])>0:\n",
    "            return 'Signal problem(s) found at index {}'.format(i)\n",
    "    \n",
    "    # Init\n",
    "    action_delay = 1 if buy_next_day else 0\n",
    "    \n",
    "    df[signals] = [long_rules[i]+short_rules[i] for i in range(len(long_rules))]  \n",
    "    df.loc[0,cash] = initial_capital\n",
    "    df.loc[0,stock] = 0\n",
    "    df.loc[0,shares] = 0\n",
    "    df.loc[0,action_completed] = 0\n",
    "    \n",
    "    def buy_shares(cash, price, commission_percent):\n",
    "        shares = cash//price\n",
    "        if price == 0:\n",
    "            return None\n",
    "        while shares*price*(1+commission_percent/100)>cash and shares > 0:\n",
    "            shares -= 1\n",
    "        return shares\n",
    "    \n",
    "    txn_list = []\n",
    "    # Iterate through the df\n",
    "    for r in range(1, len(df)):\n",
    "\n",
    "        # here 2022-11-12 \n",
    "        # debug for conflicts between the proposed action and new signal; yet selling (exit long) overrides\n",
    "        proposed_action = df.loc[r-action_delay, signals]\n",
    "        new_signal = df.loc[r, signals]\n",
    "        \n",
    "        # Long triggered\n",
    "        if proposed_action > 0 :\n",
    "#         if proposed_action > 0 and not(new_signal < 0) :\n",
    "            if df.loc[r-1, shares] == 0:\n",
    "                df.loc[r,shares] = buy_shares(cash = df.loc[r-1,cash],\\\n",
    "                                             price = df.loc[r,buy_at],\\\n",
    "                                             commission_percent = commission_percent)\n",
    "                if df.loc[r,shares] == None:\n",
    "                    print('Error: at ' + str(r))\n",
    "                \n",
    "                df.loc[r,stock] = df.loc[r,shares]*df.loc[r,buy_at]\n",
    "                df.loc[r,cash] = df.loc[r-1,cash] - df.loc[r,stock]\n",
    "                \n",
    "                # update txn_list only if a purchase is really completed\n",
    "                if df.loc[r,shares] > 0:\n",
    "                    txn_list.append([r, 1] + list(df.loc[r, [date, shares, stock, cash]]))\n",
    "                    df.loc[r,action_completed] = 1\n",
    "                else:\n",
    "                    df.loc[r,action_completed] = 0\n",
    "            else:\n",
    "                # Hold/No Action\n",
    "                df.loc[r,shares] = df.loc[r-1, shares]\n",
    "                df.loc[r,cash] = df.loc[r-1,cash]\n",
    "                df.loc[r,stock] = df.loc[r-1,stock]\n",
    "                df.loc[r,action_completed] = 0\n",
    "            \n",
    "        # Short triggered/ Selling triggered for Long-Only Appraoch\n",
    "        # Selling (exit long) overrides\n",
    "        elif proposed_action < 0:\n",
    "            df.loc[r,shares] = 0\n",
    "            df.loc[r,stock] = 0\n",
    "            df.loc[r,cash] = df.loc[r-1,cash] + df.loc[r-1,shares]*df.loc[r,buy_at]*(1-commission_percent/100)\n",
    "            # update txn_list only if a sale is really completed (ie previously holding the stock)\n",
    "            if df.loc[r-1,shares] > 0:\n",
    "                txn_list.append([r, -1] + list(df.loc[r, [date, shares, stock, cash]]))\n",
    "            \n",
    "            df.loc[r,action_completed] = 0 if df.loc[r,shares] == df.loc[r-1,shares] else -1\n",
    "\n",
    "        # Hold/No Action\n",
    "        else:\n",
    "            df.loc[r,shares] = df.loc[r-1,shares]\n",
    "            df.loc[r,stock] = df.loc[r,shares]*df.loc[r,buy_at]\n",
    "            df.loc[r,cash] = df.loc[r-1,cash]\n",
    "            df.loc[r,action_completed] = 0\n",
    "            \n",
    "    df[equity] = df[cash] + df[stock] \n",
    "    \n",
    "    return df\n",
    "       \n",
    "#     # -----------------------------------------------------------------------------------------------------\n",
    "#     # analyze the transactions\n",
    "#     def get_pct_change(x_prev, x_new, scale = 100):\n",
    "#         if x_prev == 0.:\n",
    "#             ret_sgn = np.sign([x_prev, x_new]).prod()\n",
    "#             return -math.inf if ret_sgn < 0 else math.inf\n",
    "#         else: \n",
    "#             return scale*(x_new/x_prev-1)\n",
    "    \n",
    "#     # consider each PAIR of buying and selling\n",
    "\n",
    "#     txn_df = pd.DataFrame(txn_list, columns = ['idx', 'action', 'date', 'shares', 'stock', 'cash'])\n",
    "    \n",
    "#     # buy-and-hold return % \n",
    "#     # corrected on 2022-11-10 1639\n",
    "#     bnh_pct = None\n",
    "#     if len(txn_df) >= 1:\n",
    "#         bnh_cash = txn_df.loc[0, 'cash']\n",
    "#         bnh_shares = txn_df.loc[0, 'shares']\n",
    "#         bnh_stock = txn_df.loc[0, 'stock']\n",
    "#         bnh_last_price = df.loc[len(df)-1, buy_at]\n",
    "        \n",
    "#         bnh_pct = get_pct_change(x_prev = bnh_cash + bnh_stock, \n",
    "#                                  x_new = bnh_cash + bnh_shares * bnh_last_price, \n",
    "#                                  scale = 100)\n",
    "#         print(f'here 2022-11-12 testing; {bnh_pct}')\n",
    "        \n",
    "#     if len(txn_df) >=2:\n",
    "#         txn_df['equity'] = txn_df['cash'] + txn_df['stock']\n",
    "\n",
    "#         # return of each pair of transaction\n",
    "#         i = 0\n",
    "#         txn_df['return_txnpair'] = np.nan\n",
    "#         txn_df['return_pct_txnpair'] = np.nan\n",
    "#         while i <= len(txn_list)-2:  \n",
    "#             txn_df.loc[i, 'return_txnpair'] = txn_df.loc[i+1, 'equity'] - txn_df.loc[i, 'equity']\n",
    "#             txn_df.loc[i, 'return_pct_txnpair'] = get_pct_change(x_prev = txn_df.loc[i, 'equity'], \n",
    "#                                                                  x_new = txn_df.loc[i+1, 'equity'], \n",
    "#                                                                  scale = 100)\n",
    "#             i+=2\n",
    "        \n",
    "#         # net profit %\n",
    "#         profit_net_pct = get_pct_change(x_prev = df.loc[df.index[0],equity], \n",
    "#                                         x_new = df.loc[df.index[-1],equity], \n",
    "#                                         scale = 100)\n",
    "        \n",
    "# #         print(f'profit_net_pct: {profit_net_pct}')\n",
    "        \n",
    "#         # gross profit, gross loss, and their %\n",
    "#         profit_gross = txn_df[txn_df['return_txnpair'] > 0]['return_txnpair'].sum()\n",
    "#         profit_gross_pct = get_pct_change(x_prev = initial_capital, \n",
    "#                                           x_new = initial_capital+profit_gross, \n",
    "#                                           scale = 100)\n",
    "# #         print(f'profit_net_pct: {profit_net_pct}')\n",
    "        \n",
    "#         loss_gross = txn_df[txn_df['return_txnpair'] <= 0]['return_txnpair'].sum()\n",
    "#         loss_gross_pct = get_pct_change(x_prev = initial_capital, \n",
    "#                                         x_new = initial_capital+loss_gross, \n",
    "#                                         scale = 100)\n",
    "# #         print(f'loss_gross_pct: {loss_gross_pct}')\n",
    "        \n",
    "#         # profit factor\n",
    "#         profit_factor = profit_gross / loss_gross if abs(loss_gross) > 0 else 10**9    # prevent DivisionByZero\n",
    "        \n",
    "# #         print(f'profit_factor: {profit_factor}')\n",
    "\n",
    "#         # max run-up and max draw-down\n",
    "#         runup_pct_max = txn_df['return_pct_txnpair'].max()\n",
    "#         drawdown_pct_max = txn_df['return_pct_txnpair'].min()    # using min because the drawdown % is neg\n",
    "        \n",
    "# #         print(f'runup_pct_max: {runup_pct_max}')\n",
    "# #         print(f'drawdown_pct_max: {drawdown_pct_max}')\n",
    "\n",
    "#         # Sharpe & Sortino; Avg Trade (geo mean) (mean_return_pct_annual)\n",
    "#         # Also the avg winning trade and avg losing trade\n",
    "#         dayscount_backtest = len(df)    # neglect days without prices, eg public holidays\n",
    "# #         print(f'dayscount_backtest: {dayscount_backtest}')\n",
    "\n",
    "#         mean_return_pct_annual = txn_df['return_pct_txnpair'].dropna().apply(lambda x: x/100 + 1)\n",
    "#         mean_return_pct_annual = np.power(mean_return_pct_annual.product(), 250/dayscount_backtest)-1    # assume 250 trading days annually\n",
    "# #         print(f'mean_return_pct_annual: {mean_return_pct_annual}')\n",
    "        \n",
    "#         sd_return_pct_annual = txn_df['return_pct_txnpair'].std(ddof = 0)\n",
    "        \n",
    "#         sd_return_pct_annual *= np.sqrt(dayscount_backtest)    # assume daily data input, and so annualized by multiplying sqrt(days coount)\n",
    "# #         print(f'sd_return_pct_annual: {sd_return_pct_annual}')\n",
    "        \n",
    "#         sd_downside_return_pct_annual = txn_df[txn_df['return_pct_txnpair'] <= 0]['return_pct_txnpair'].std(ddof = 0)\n",
    "#         sd_downside_return_pct_annual *= np.sqrt(dayscount_backtest)    # assume daily data input, and so annualized by multiplying sqrt(days coount)\n",
    "# #         print(f'sd_downside_return_pct_annual: {sd_downside_return_pct_annual}')\n",
    "        \n",
    "#         sharpe_annual = None if math.isnan(sd_return_pct_annual) or sd_return_pct_annual == 0. else \\\n",
    "#         (mean_return_pct_annual - risk_free_rate)/sd_return_pct_annual\n",
    "        \n",
    "#         sortino_annual = None if math.isnan(sd_downside_return_pct_annual) or sd_downside_return_pct_annual == 0. else \\\n",
    "#         (mean_return_pct_annual - risk_free_rate)/sd_downside_return_pct_annual\n",
    "\n",
    "#         # Avg winning trade\n",
    "#         # here debug 2022-11-04 WIP\n",
    "#         avg_loss_pct_annual = None\n",
    "#         avg_win_pct_annual = None\n",
    "#         avg_wintoloss_ratio_annual = None\n",
    "        \n",
    "# #         if math.isnan(mean_return_pct_annual[mean_return_pct_annual > 0].prod()):\n",
    "# #             avg_win_pct_annual = None\n",
    "# #         else:\n",
    "# #             avg_win_pct_annual = np.power(mean_return_pct_annual[mean_return_pct_annual > 0].prod(), 250/dayscount_backtest)-1\n",
    "        \n",
    "# #         # Avg losing trade\n",
    "# #         if math.isnan(mean_return_pct_annual[mean_return_pct_annual <= 0]):\n",
    "# #             avg_loss_pct_annual = None\n",
    "# #         else:\n",
    "# #             avg_loss_pct_annual = np.power(mean_return_pct_annual[mean_return_pct_annual <= 0].prod(), 250/dayscount_backtest)-1\n",
    "            \n",
    "# #         # Avg Win-to-Loss Ratio\n",
    "# #         if avg_loss_pct_annual == None or avg_win_pct_annual == None:\n",
    "# #             avg_wintoloss_ratio_annual = None\n",
    "# #         elif avg_loss_pct_annual == 0:\n",
    "# #             avg_wintoloss_ratio_annual = math.inf\n",
    "# #         else:\n",
    "# #             avg_wintoloss_ratio_annual = avg_win_pct_annual/avg_loss_pct_annual\n",
    "\n",
    "#         # Max Contracts Held (max_shares)\n",
    "#         max_shares = txn_df['shares'].max()\n",
    "\n",
    "#         # Number Winning Trades and Losing Trades and win rate (win_pct)\n",
    "#         txn_pairs = txn_df['return_pct_txnpair'].dropna()\n",
    "#         win_count = len(txn_pairs[txn_pairs>0])\n",
    "#         loss_count = len(txn_pairs[txn_pairs<=0])\n",
    "#         win_pct = 100*win_count/len(txn_pairs)  \n",
    "        \n",
    "# #         print(f'win_count, loss_count, win_pct: {win_count}, {loss_count}, {win_pct}')\n",
    "\n",
    "#         txn_summary = {'bnh_pct': bnh_pct, \n",
    "#                        'profit_net_pct': profit_net_pct, \n",
    "#                        'profit_gross_pct': profit_gross_pct, \n",
    "#                        'loss_gross_pct': loss_gross_pct, \n",
    "#                        'profit_factor': profit_factor, \n",
    "#                        'runup_pct_max': runup_pct_max, \n",
    "#                        'drawdown_pct_max': drawdown_pct_max, \n",
    "#                        'mean_return_pct_annual': mean_return_pct_annual, \n",
    "#                        'sd_return_pct_annual': sd_return_pct_annual, \n",
    "#                        'sd_downside_return_pct_annual': sd_downside_return_pct_annual, \n",
    "#                        'risk_free_rate': risk_free_rate,\n",
    "#                        'sharpe_annual': sharpe_annual, \n",
    "#                        'sortino_annual': sortino_annual, \n",
    "#                        'avg_win_pct_annual': avg_win_pct_annual, \n",
    "#                        'avg_loss_pct_annual': avg_loss_pct_annual, \n",
    "#                        'avg_wintoloss_ratio_annual': avg_wintoloss_ratio_annual, \n",
    "#                        'max_shares': max_shares, \n",
    "#                        'win_count': win_count, \n",
    "#                        'loss_count':loss_count,\n",
    "#                        'win_pct': win_pct, \n",
    "#                        'txn_list': txn_list}\n",
    "#     else:\n",
    "#         txn_summary = {'bnh_pct': bnh_pct, \n",
    "#                        'profit_net_pct': None, \n",
    "#                        'profit_gross_pct': None, \n",
    "#                        'loss_gross_pct': None, \n",
    "#                        'profit_factor': None, \n",
    "#                        'runup_pct_max': None, \n",
    "#                        'drawdown_pct_max': None, \n",
    "#                        'mean_return_pct_annual': None, \n",
    "#                        'sd_return_pct_annual': None, \n",
    "#                        'sd_downside_return_pct_annual': None, \n",
    "#                        'risk_free_rate': risk_free_rate,\n",
    "#                        'sharpe_annual': None, \n",
    "#                        'sortino_annual': None, \n",
    "#                        'avg_win_pct_annual': 0, \n",
    "#                        'avg_loss_pct_annual': None, \n",
    "#                        'avg_wintoloss_ratio_annual': None, \n",
    "#                        'max_shares': 0, \n",
    "#                        'win_count': 0, \n",
    "#                        'loss_count':0,\n",
    "#                        'win_pct': 0, \n",
    "#                        'txn_list': txn_list}\n",
    "    \n",
    "\n",
    "    \n",
    "# #     # testing, wait for debug\n",
    "# #     # debug here 2022-10-31 0204\n",
    "    \n",
    "# #     txn_df = pd.DataFrame()\n",
    "# #     txn_summary = dict()\n",
    "    \n",
    "#     return (df, txn_df, txn_summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# debug here 2022-11-13 1017 (WIP)\n",
    "# for debugging and testing\n",
    "long_rules = df_temp['actions'].apply(lambda x: 1 if x == 1 else 0).to_list()\n",
    "short_rules = df_temp['actions'].apply(lambda x: -1 if x == -1 else 0).to_list()\n",
    "ret = backtest(df_temp, long_rules = long_rules, short_rules = short_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ret.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.434889/8.433067-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ret['delta(KAMA(Close_ln, 10, 4, 10), 2)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ret['delta(KAMA(Close_ln, 10, 4, 10), 2)'].apply(lambda x: x-param_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ret[['KAMA(Close_ln, 10, 4, 10)',\n",
    "              'KAMA-Mean(Close_ln, 10, 4, 10, 23)','Close_ln']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ret['long_actions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Version 2\n",
    "\n",
    "# # @jit(target_backend='cuda') \n",
    "# def backtest(df, long_rules, short_rules, long_only = True, \\\n",
    "#              initial_capital=100000, commission_percent=0.5, risk_free_rate = 5, \\\n",
    "#              buy_next_day=True, date='Date', buy_at = 'Close',\\\n",
    "#              signals='Signals', shares='Shares', cash='Cash', stock='Stock', equity='Equity'):\n",
    "    \n",
    "#     df = df.copy()\n",
    "#     df.reset_index(drop=False, inplace=True)\n",
    "    \n",
    "#     # Assume no short selling allowed\n",
    "#     # ie sell holing stocks whenever a short signal is triggered\n",
    "    \n",
    "#     # Check for any conflicts between long_rules and short_rules\n",
    "#     for i in range(len(long_rules)):\n",
    "#         # Cannot long/short at the same time\n",
    "#         if abs(long_rules[i])>0 and abs(short_rules[i])>0:\n",
    "#             return 'Signal problem(s) found at index {}'.format(i)\n",
    "    \n",
    "#     # Init\n",
    "#     action_delay = 1 if buy_next_day else 0\n",
    "    \n",
    "#     df[signals] = [long_rules[i]+short_rules[i] for i in range(len(long_rules))]\n",
    "#     df.loc[0,cash] = initial_capital\n",
    "#     df.loc[0,stock] = 0\n",
    "#     df.loc[0,shares] = 0\n",
    "    \n",
    "#     def buy_shares(cash, price, commission_percent):\n",
    "#         shares = cash//price\n",
    "#         if price == 0:\n",
    "#             return None\n",
    "#         while shares*price*(1+commission_percent/100)>cash and shares > 0:\n",
    "#             shares -= 1\n",
    "#         return shares\n",
    "    \n",
    "#     txn_list = []\n",
    "#     # Iterate through the df\n",
    "#     for r in range(1, len(df)):\n",
    "\n",
    "#         # Long triggered\n",
    "#         if df.loc[r-action_delay, signals] > 0:\n",
    "#             if df.loc[r-1, shares] == 0:\n",
    "#                 df.loc[r,shares] = buy_shares(cash = df.loc[r-1,cash],\\\n",
    "#                                              price = df.loc[r,buy_at],\\\n",
    "#                                              commission_percent = commission_percent)\n",
    "#                 if df.loc[r,shares] == None:\n",
    "#                     print('Error: at ' + str(r))\n",
    "                \n",
    "#                 df.loc[r,stock] = df.loc[r,shares]*df.loc[r,buy_at]\n",
    "#                 df.loc[r,cash] = df.loc[r-1,cash] - df.loc[r,stock]\n",
    "#                 txn_list.append([r] + list(df.loc[r, [date, shares, stock, cash]]))\n",
    "#             else:\n",
    "#                 df.loc[r,shares] = df.loc[r-1, shares]\n",
    "#                 df.loc[r,cash] = df.loc[r-1,cash]\n",
    "#                 df.loc[r,stock] = df.loc[r-1,stock]\n",
    "            \n",
    "#         # Short triggered/ Selling triggered for Long-Only Appraoch\n",
    "#         elif df.loc[r-action_delay, signals] < 0:\n",
    "#             df.loc[r,shares] = 0\n",
    "#             df.loc[r,stock] = 0\n",
    "#             df.loc[r,cash] = df.loc[r-1,cash] + df.loc[r-1,shares]*df.loc[r,buy_at]*(1-commission_percent/100)\n",
    "#             txn_list.append([r] + list(df.loc[r, [date, shares, stock, cash]]))\n",
    "\n",
    "#         # Hold/No Action\n",
    "#         else:\n",
    "#             df.loc[r,shares] = df.loc[r-1,shares]\n",
    "#             df.loc[r,stock] = df.loc[r,shares]*df.loc[r,buy_at]\n",
    "#             df.loc[r,cash] = df.loc[r-1,cash]\n",
    "            \n",
    "#     df[equity] = df[cash] + df[stock] \n",
    "    \n",
    "#     # -----------------------------------------------------------------------------------------------------\n",
    "#     # analyze the transactions\n",
    "#     def get_pct_change(x_prev, x_new, scale = 100):\n",
    "#         return scale*(x_new/x_prev-1)\n",
    "    \n",
    "#     # consider each PAIR of buying and selling\n",
    "#     # buy-and-hold return % \n",
    "#     bnh_pct = get_pct_change(x_prev = df.loc[df.index[0],equity], \n",
    "#                              x_new = df.loc[df.index[-1],equity], \n",
    "#                              scale = 100) \n",
    "#     txn_df = pd.DataFrame(txn_list, columns = ['idx', 'date', 'shares', 'stock', 'cash'])\n",
    "#     if len(txn_df) >=2:\n",
    "#         txn_df['equity'] = txn_df['cash'] + txn_df['stock']\n",
    "\n",
    "#         # return of each pair of transaction\n",
    "#         i = 0\n",
    "#         txn_df['return_txnpair'] = np.nan\n",
    "#         txn_df['return_pct_txnpair'] = np.nan\n",
    "#         while i <= len(txn_list)-2:  \n",
    "#             txn_df.loc[i, 'return_txnpair'] = txn_df.loc[i+1, 'equity'] - txn_df.loc[i, 'equity']\n",
    "#             txn_df.loc[i, 'return_pct_txnpair'] = get_pct_change(x_prev = txn_df.loc[i, 'equity'], \n",
    "#                                                                  x_new = txn_df.loc[i+1, 'equity'], \n",
    "#                                                                  scale = 100)\n",
    "#             i+=2\n",
    " \n",
    "#         # net profit %\n",
    "#         profit_net_pct = get_pct_change(x_prev = df.loc[df.index[0],buy_at], \n",
    "#                                         x_new = df.loc[df.index[-1],buy_at], \n",
    "#                                         scale = 100)\n",
    "#         # gross profit, gross loss, and their %\n",
    "#         profit_gross = txn_df[txn_df['return_txnpair'] > 0].sum()\n",
    "#         profit_gross_pct = get_pct_change(x_prev = initial_capital, \n",
    "#                                           x_new = initial_capital+profit_gross, \n",
    "#                                           scale = 100)\n",
    "#         loss_gross = txn_df[txn_df['return_txnpair'] <= 0].sum()\n",
    "#         loss_gross_pct = get_pct_change(x_prev = initial_capital, \n",
    "#                                         x_new = initial_capital+loss_gross, \n",
    "#                                         scale = 100)\n",
    "#         # profit factor\n",
    "#         profit_factor = profit_gross / loss_gross\n",
    "\n",
    "#         # max run-up and max draw-down\n",
    "#         runup_pct_max = txn_df['return_pct_txnpair'].max()\n",
    "#         drawdown_pct_max = txn_df['return_pct_txnpair'].min()    # using min because the drawdown % is neg\n",
    "\n",
    "#         # Sharpe & Sortino; Avg Trade (geo mean) (mean_return_pct_annual)\n",
    "#         # Also the avg winning trade and avg losing trade\n",
    "#         dayscount_backtest = len(df)    # neglect days without prices, eg public holidays\n",
    "\n",
    "#         mean_return_pct_annual = txn_df['return_pct_txnpair'].dropna().apply(lambda x: x/100 + 1)\n",
    "#         mean_return_pct_annual = np.power(mean_return_pct_annual.product(), 250/dayscount_backtest)-1    # assume 250 trading days annually\n",
    "\n",
    "#         sd_return_pct_annual = txn_df['return_pct_txnpair'].std(ddof = 0)\n",
    "#         sd_return_pct_annual *= np.sqrt(dayscount_backtest)    # assume daily data input, and so annualized by multiplying sqrt(days coount)\n",
    "\n",
    "#         sd_downside_return_pct_annual = txn_df[txn_df['return_pct_txnpair'] <= 0].std(ddof = 0)\n",
    "#         sd_downside_return_pct_annual *= np.sqrt(dayscount_backtest)    # assume daily data input, and so annualized by multiplying sqrt(days coount)\n",
    "\n",
    "#         sharpe_annual = (mean_return_pct_annual - risk_free_rate)/sd_return_pct_annual\n",
    "#         sortino_annual = (mean_return_pct_annual - risk_free_rate)/sd_downside_return_pct_annual\n",
    "\n",
    "#         # Avg winning trade, avg losing trade, and their ratio\n",
    "#         avg_win_pct_annual = np.power(mean_return_pct_annual[mean_return_pct_annual > 0].prod(), 250/dayscount_backtest)-1\n",
    "#         avg_loss_pct_annual = np.power(mean_return_pct_annual[mean_return_pct_annual <= 0].prod(), 250/dayscount_backtest)-1\n",
    "#         avg_wintoloss_ratio_annual = avg_win_pct_annual/avg_loss_pct_annual\n",
    "\n",
    "#         # Max Contracts Held (max_shares)\n",
    "#         max_shares = txn_df['shares'].max()\n",
    "\n",
    "#         # Number Winning Trades and win rate (win_pct)\n",
    "#         txn_pairs = txn_df['return_pct_txnpair'].dropna()\n",
    "#         win_count = len(txn_pairs[txn_pairs>0])\n",
    "#         win_pct = 100*win_count/len(txn_pairs)        \n",
    "\n",
    "#         txn_summary = {'bnh_pct': bnh_pct, \n",
    "#                        'profit_net_pct': profit_net_pct, \n",
    "#                        'profit_gross_pct': profit_gross_pct, \n",
    "#                        'loss_gross_pct': loss_gross_pct, \n",
    "#                        'profit_factor': profit_factor, \n",
    "#                        'runup_pct_max': runup_pct_max, \n",
    "#                        'drawdown_pct_max': drawdown_pct_max, \n",
    "#                        'mean_return_pct_annual': mean_return_pct_annual, \n",
    "#                        'sd_return_pct_annual': sd_return_pct_annual, \n",
    "#                        'sd_downside_return_pct_annual': sd_downside_return_pct_annual, \n",
    "#                        'risk_free_rate': risk_free_rate,\n",
    "#                        'sharpe_annual': sharpe_annual, \n",
    "#                        'sortino_annual': sortino_annual, \n",
    "#                        'avg_win_pct_annual': avg_win_pct_annual, \n",
    "#                        'avg_loss_pct_annual': avg_loss_pct_annual, \n",
    "#                        'avg_wintoloss_ratio_annual': avg_wintoloss_ratio_annual, \n",
    "#                        'max_shares': max_shares, \n",
    "#                        'win_count': win_count, \n",
    "#                        'win_pct': win_pct}\n",
    "#     else:\n",
    "#         txn_summary = {'bnh_pct': bnh_pct, \n",
    "#                        'profit_net_pct': None, \n",
    "#                        'profit_gross_pct': None, \n",
    "#                        'loss_gross_pct': None, \n",
    "#                        'profit_factor': None, \n",
    "#                        'runup_pct_max': None, \n",
    "#                        'drawdown_pct_max': None, \n",
    "#                        'mean_return_pct_annual': None, \n",
    "#                        'sd_return_pct_annual': None, \n",
    "#                        'sd_downside_return_pct_annual': None, \n",
    "#                        'risk_free_rate': risk_free_rate,\n",
    "#                        'sharpe_annual': None, \n",
    "#                        'sortino_annual': None, \n",
    "#                        'avg_win_pct_annual': None, \n",
    "#                        'avg_loss_pct_annual': None, \n",
    "#                        'avg_wintoloss_ratio_annual': None, \n",
    "#                        'max_shares': None, \n",
    "#                        'win_count': 0, \n",
    "#                        'win_pct': None}\n",
    "    \n",
    "#     # testing, wait for debug\n",
    "#     # debug here 2022-10-31 0204\n",
    "    \n",
    "# #     txn_df = pd.DataFrame()\n",
    "# #     txn_summary = dict()\n",
    "    \n",
    "#     return (df, txn_df, txn_summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(target_backend='cuda')\n",
    "def add_dc(df, dc_source, dc_len, bound_pct = 0, bound = 'both'):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if bound.lower() == 'upper':\n",
    "        df['{}-Period High'.format(dc_len)] = df[dc_source].rolling(dc_len).max().apply(lambda x: (1+bound_pct)*x)\n",
    "    \n",
    "    elif bound.lower() == 'lower':\n",
    "        df['{}-Period Low'.format(dc_len)] = df[dc_source].rolling(dc_len).min().apply(lambda x: (1-bound_pct)*x)\n",
    "    \n",
    "    elif bound == 'both':\n",
    "        df['{}-Period High'.format(dc_len)] = df[dc_source].rolling(dc_len).max().apply(lambda x: (1+bound_pct)*x)\n",
    "        df['{}-Period Low'.format(dc_len)] = df[dc_source].rolling(dc_len).min().apply(lambda x: (1-bound_pct)*x)\n",
    "    else:\n",
    "        assert False, '\\'bound\\' is expected to be either \\'upper\\', \\'lower\\', or \\'both\\'.'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here 2022-11-05 0951 WIP\n",
    "# assert False, 'here 2022-11-05 0951 WIP'\n",
    "def add_kama(df, src_colname, delta_len = 10, fast_len = 2, slow_len = 30, with_kama_mean = True, kama_mean_len = 25, fillna = False):\n",
    "    df = df.copy()\n",
    "    kama = ta.momentum.kama(close=df[src_colname], \n",
    "                            window = delta_len, \n",
    "                            pow1 = fast_len, \n",
    "                            pow2 = slow_len, \n",
    "                            fillna = False)\n",
    "    df[f'KAMA({src_colname}, {delta_len}, {fast_len}, {slow_len})'] = kama\n",
    "    if with_kama_mean:\n",
    "        # shifted KAMA by the mean of residual within a rolling window\n",
    "        rsd = df[src_colname] - kama                          # kama here is the original KAMA\n",
    "        rsd_mean = rsd.rolling(kama_mean_len).mean()\n",
    "        kama_mean = kama + rsd_mean                           # shifted KAMA-Mean\n",
    "        df[f'KAMA-Mean({src_colname}, {delta_len}, {fast_len}, {slow_len}, {kama_mean_len})'] = kama_mean  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(inp_list):\n",
    "    # last value - start value\n",
    "    return inp_list[-1] - inp_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution: \n",
    "# 1. df_temp is to be assigned OUTSIDE the function below\n",
    "# 2. input of the function below CANNOT be changed, or otherwise optimization cannot be performed.\n",
    "\n",
    "# @jit(target_backend='cuda')\n",
    "def objective_func(x):\n",
    "    global df_temp, df_bt, txn_df, txn_summary\n",
    "    \n",
    "    # ==============================================================================================\n",
    "    # KAMA-Mean\n",
    "    # here 2022-11-05 0951\n",
    "    n_delta, n_fast, n_slow, delta_lim_up, delta_lim_dn, delta_lim_len, kama_mean_len = x\n",
    "    \n",
    "    src_name = 'Close_ln'\n",
    "    n_delta = int(round(n_delta,0))    # ensure integer\n",
    "    n_fast = int(round(n_fast,0))      # ensure integer\n",
    "    n_slow = int(round(n_slow,0))      # ensure integer\n",
    "    kama_mean_len = int(round(kama_mean_len, 0))    # ensure integer\n",
    "    delta_lim_len = int(round(delta_lim_len, 0))    # ensure integer\n",
    "    \n",
    "    df_temp = add_kama(df = df_temp, \n",
    "                       src_colname = src_name, \n",
    "                       delta_len = n_delta, \n",
    "                       fast_len = n_fast, \n",
    "                       slow_len = n_slow, \n",
    "                       with_kama_mean = True, \n",
    "                       kama_mean_len = kama_mean_len, \n",
    "                       fillna = False)\n",
    "    \n",
    "    ub_col = f'KAMA({src_name}, {n_delta}, {n_fast}, {n_slow})'\n",
    "    lb_col = f'KAMA-Mean({src_name}, {n_delta}, {n_fast}, {n_slow}, {kama_mean_len})'\n",
    "    kama_delta_col = f'delta({ub_col}, {delta_lim_len})'\n",
    "    \n",
    "    kama_delta = df_temp[ub_col].rolling(delta_lim_len).apply(lambda x: delta(list(x)))    # Caution: delta of KAMA, not of KAMA-Mean\n",
    "    df_temp[kama_delta_col] = kama_delta    # Caution: delta of KAMA, not of KAMA-Mean\n",
    "    \n",
    "#     # here 2022-11-11 1156\n",
    "#     # drop the first extra_len_init rows of data\n",
    "#     # these rows are just needed for prevention of NaN values in the indicator column(s) (ie KAMA and KAMA-Mean)\n",
    "#     df_temp.drop(df_temp.index[:extra_len_init], inplace=True)\n",
    "    \n",
    "    # buying / selling actions \n",
    "    long_actions = df_temp[kama_delta_col] - delta_lim_up\n",
    "    long_actions = long_actions.apply(lambda x: 1 if x > 0 else None)\n",
    "    df_temp['long_actions'] = long_actions  \n",
    "\n",
    "    short_actions = df_temp[src_name] - df_temp[lb_col]\n",
    "    short_actions = short_actions.apply(lambda x: -1 if x < 0 else None)\n",
    "    df_temp['short_actions'] = short_actions\n",
    "    \n",
    "    # ==============================================================================================\n",
    "    \n",
    "#     # ==============================================================================================\n",
    "#     # DC\n",
    "\n",
    "#     global n_up_interval, n_dn_interval\n",
    "\n",
    "#     # init\n",
    "#     n_up, n_dn, bound_up_pct, bound_dn_pct = x    \n",
    "#     n_up = int(round(n_up,0))    # ensure integer\n",
    "#     n_dn = int(round(n_dn,0))    # ensure integer\n",
    "    \n",
    "#     n_up *= n_up_interval\n",
    "#     n_dn *= n_dn_interval\n",
    "    \n",
    "#     # ----------------------------------\n",
    "#     # add DC bounds\n",
    "#     df_temp = add_dc(df = df_temp, \n",
    "#                      dc_source = 'Close', \n",
    "#                      dc_len = n_up, \n",
    "#                      bound_pct = 0, \n",
    "#                      bound = 'upper')\n",
    "#     df_temp = add_dc(df = df_temp, \n",
    "#                      dc_source = 'Close', \n",
    "#                      dc_len = n_dn, \n",
    "#                      bound_pct = 0, \n",
    "#                      bound = 'lower')\n",
    "#     ub_col = f'{n_up}-Period High'\n",
    "#     lb_col = f'{n_dn}-Period Low'\n",
    "    \n",
    "#     # buying / selling actions \n",
    "#     long_actions = (df_temp['Close'] / df_temp[ub_col].shift(1) - 1) - bound_up_pct\n",
    "#     long_actions = long_actions.apply(lambda x: 1 if x > 0 else None)\n",
    "#     df_temp['long_actions'] = long_actions  \n",
    "\n",
    "#     short_actions = (df_temp['Close'] / df_temp[lb_col].shift(1) - 1) - bound_dn_pct\n",
    "#     short_actions = short_actions.apply(lambda x: -1 if x < 0 else None)\n",
    "#     df_temp['short_actions'] = short_actions\n",
    "    \n",
    "#     # ==============================================================================================\n",
    "    \n",
    "    \n",
    "    # integrate the buying and selling actions (ie a signal)\n",
    "    # no delay is assumed\n",
    "    actions = pd.Series(zip(long_actions, short_actions))\n",
    "    del long_actions, short_actions\n",
    "    \n",
    "    actions = actions.apply(lambda x: -1 if x[1] == -1 else 1 if x[0] == 1 else 0)\n",
    "    df_temp['actions'] = list(actions)    # must turn into a list so as to prevent future errors out of non-matching index\n",
    "    \n",
    "    del actions\n",
    "    \n",
    "    # debug here 2022-11-03 0004 WIP\n",
    "    # testing\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # backtest\n",
    "    # input\n",
    "    initial_capital = 10**5\n",
    "    long_rules = df_temp['actions'].apply(lambda x: 1 if x == 1 else 0).to_list()\n",
    "    short_rules = df_temp['actions'].apply(lambda x: -1 if x == -1 else 0).to_list()\n",
    "    buy_at = 'Close'\n",
    "    commission_percent = 0.5\n",
    "    buy_next_day = True\n",
    "\n",
    "    df_bt, txn_df, txn_summary = backtest(df = df_temp, \n",
    "                                          long_rules = long_rules,\n",
    "                                          short_rules = short_rules,\n",
    "                                          buy_at = buy_at,\n",
    "                                          initial_capital = initial_capital, \n",
    "                                          commission_percent = commission_percent, \n",
    "                                          buy_next_day = buy_next_day)\n",
    "    \n",
    "    bt_return_pct = 100*(df_bt.loc[df_bt.index[-1], 'Equity']/initial_capital-1)\n",
    "    bt_return_pct_signflipped = -bt_return_pct\n",
    "    win_count = txn_summary['win_count']\n",
    "    loss_count = txn_summary['loss_count']\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # objective function\n",
    "        \n",
    "#     # version 1\n",
    "#     bt_ret = bt_return_pct_signflipped\n",
    "    \n",
    "#     # version 2\n",
    "#     bt_ret = bt_return_pct_signflipped + - win_count**2\n",
    "    \n",
    "#     # version 3\n",
    "    bt_ret = - win_count**2 + loss_count**2\n",
    "    \n",
    "    # version 4\n",
    "#     bt_ret = - bt_return_pct - win_count**2 + loss_count**2\n",
    "    \n",
    "#     print(f'bt_ret, win_count, bt_return_pct, x\\': {bt_ret}, {win_count}, {bt_return_pct}, {[n_up, n_dn, bound_up_pct, bound_dn_pct]}')\n",
    "\n",
    "    return bt_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test = pd.DataFrame({'Date': df.loc[0:23, 'Date'], 'Close': list(range(12)) + [12 - i for i in range(12)]})\n",
    "# # test = add_dc( df = test, dc_source = 'Close', dc_len = 5)\n",
    "# test\n",
    "# # =====================================================\n",
    "# df_temp = test.copy()\n",
    "# n_up_interval, n_dn_interval = 5, 5\n",
    "# objective_func([1,1,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# from scipy import optimize\n",
    "# import datetime as dt\n",
    "# import winsound\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# inputs\n",
    "# inputs for results output and notifications in telegram\n",
    "output_folder = r\"C:\\Users\\Planet Edu\\OneDrive\\Tutor 導師\\George\\temp\\temp outputs\\2022-11-13 (PlanetEdu DT)\"\n",
    "token = '5651860543:AAEbzdr2mlQUlaU8UELy-vHEnpY-_drKvbw'\n",
    "chat_id ='-832118262'\n",
    "\n",
    "# inputs for data separation into training and testing set\n",
    "rows_toview = 18077                        # define the start of the 1st period for training and testing\n",
    "period_toview = 250*2 + 125                # 2.5 years\n",
    "train_pct = 0.8                            # normally taken as 0.7 ~ 0.8\n",
    "\n",
    "# inputs for optimization\n",
    "optim_model = 'DA'     # this is just for showing in the returning results\n",
    "maxiter = 1000\n",
    "seed = 1\n",
    "\n",
    "checker = 0    # a checker to ensure only 1 strategy is to be tested\n",
    "\n",
    "# inputs for the bounds for optimization: \n",
    "# =======================================================================================================\n",
    "# KAMA & KAMA-Mean\n",
    "# n_delta, n_fast, n_slow, delta_lim_up, delta_lim_dn, delta_lim_len, kama_mean_len\n",
    "strat_name = 'KAMA with KAMA-Mean'\n",
    "bounds = [(3, 20), \n",
    "          (2, 5), (10, 100), \n",
    "          (0, 0.1), (0, 0.1), \n",
    "          (2, 5), (5, 100)]\n",
    "\n",
    "# # here 2022-11-11 1156\n",
    "# # consider extra prev data to generate values of KAMA-Mean in the beginning days so as to prevent NaN in these days\n",
    "# # kama_mean_len + delta_lim_len + max(n_slow, n_fast, n_delta)\n",
    "# extra_len_init = 1 + bounds[6][1] + bounds[5][1] + max(bounds[0][1], bounds[1][1], bounds[2][1])\n",
    "    \n",
    "checker += 1\n",
    "# # =======================================================================================================\n",
    "# # DC\n",
    "# # inputs for the bounds for optimization: \n",
    "# # n_up (to be multiplied by the interval), n_dn (to be multiplied by 10), bound_up_pct, bound_dn_pct\n",
    "# strat_name = 'DC'\n",
    "# bounds = [(1, 20), (1, 20), \n",
    "#           (0, 0.1), (0, 0.1)]\n",
    "\n",
    "# n_up_interval = 5\n",
    "# n_dn_interval = 5\n",
    "\n",
    "# checker += 1\n",
    "\n",
    "# =======================================================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "assert checker == 1., f\"Only 1 stategy can be tested each time, but there are {checker} detected! Check the codes corresponding to the inputs part.\"\n",
    "del checker\n",
    "\n",
    "print(f'''\n",
    "token: {token}\n",
    "chat_id: {chat_id}\n",
    "''')\n",
    "\n",
    "param_info = f'''\n",
    "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "strat_name: {strat_name}\n",
    "dt.datetime.now(): {dt.datetime.now()}\n",
    "\n",
    "Param.\n",
    "\n",
    "output_folder: {output_folder}\n",
    "rows_toview: {rows_toview}\n",
    "period_toview: {period_toview}\n",
    "train_pct: {train_pct}\n",
    "maxiter: {maxiter}\n",
    "seed: {seed}\n",
    "bounds: {bounds}\n",
    "extra_len_init: {extra_len_init}\n",
    "'''\n",
    "print(param_info)\n",
    "\n",
    "# print('\\nXXXXXXXXfXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\n')\n",
    "# print(f'strat_name: {strat_name}\\n')\n",
    "# print('Param.\\n')\n",
    "# print(f'output_folder: {output_folder}')\n",
    "# print(f'rows_toview: {rows_toview}')\n",
    "# print(f'period_toview: {period_toview}')\n",
    "# print(f'train_pct: {train_pct}')\n",
    "# print(f'maxiter: {maxiter}')\n",
    "# print(f'bounds: {bounds}')\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# init.\n",
    "\n",
    "period_test = int(round((1-train_pct)*period_toview,0))\n",
    "\n",
    "# get intervals for traing and testing\n",
    "print('\\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\\n')\n",
    "print('\\nIntervals of Periods: \\n')\n",
    "\n",
    "periods = [((rows_toview+period_test*i, df.loc[rows_toview+period_test*i, 'Date']), \n",
    "            (rows_toview+period_test*i+period_toview-1, df.loc[rows_toview+period_test*i+period_toview-1, 'Date'])) for i in range(40)]\n",
    "# # Superseded\n",
    "# # Originally, in the trial, overall periods for training and testing are defined as below:\n",
    "# periods = [((rows_toview+period_toview*i, df.loc[rows_toview+period_toview*i, 'Date']), \n",
    "#             (rows_toview+period_toview*(i+1)-1, df.loc[rows_toview+period_toview*(i+1)-1, 'Date'])) for i in range(9)]\n",
    "\n",
    "\n",
    "for p in range(len(periods)):\n",
    "    print((p, periods[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the param_info in telegram\n",
    "send_to_telegram(message = param_info, \n",
    "                 token=token, \n",
    "                 chat_id=chat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get % return for each testing and training period if\n",
    "##### <<  just buy on 1st day and sell on the last day of the period >>\n",
    "(only need to run once and save the results for future use if\n",
    "periods for training and testing are unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here 2022-11-10 1358\n",
    "# # get ret_pct for each testing period if \n",
    "# # just buy on 1st day and sell on the last day of the period\n",
    "\n",
    "# ret_list = []\n",
    "\n",
    "# for p in range(0,len(periods)):             # doing in order \n",
    "               \n",
    "#     # get rows for training and testing\n",
    "#     rows_train = periods[p][0][0], periods[p][0][0] + int(period_toview*train_pct)      \n",
    "#     rows_test = rows_train[-1] + 1, periods[p][1][0]\n",
    "    \n",
    "#     df_summary = df.loc[rows_train[0]: rows_test[1], ['Date', 'Close', 'Close_ln']].copy()\n",
    "    \n",
    "#     # for the training period\n",
    "#     df_train = df_summary.loc[rows_train[0]:rows_train[1],]\n",
    "#     date_from = df_train.loc[rows_train[0],'Date']\n",
    "#     date_to = df_train.loc[rows_train[1],'Date']\n",
    "#     ret_pct = 100 * (df_train.loc[rows_train[1], 'Close'] / df_train.loc[rows_train[0], 'Close'] - 1)     # scaled to 100\n",
    "    \n",
    "#     ret_list.append(['Training', date_from, date_to, ret_pct])\n",
    "    \n",
    "#     # for the testing period\n",
    "#     df_test = df_summary.loc[rows_test[0]:rows_test[1],]\n",
    "#     date_from = df_test.loc[rows_test[0],'Date']\n",
    "#     date_to = df_test.loc[rows_test[1],'Date']\n",
    "#     ret_pct = 100 * (df_test.loc[rows_test[1], 'Close'] / df_test.loc[rows_test[0], 'Close'] - 1)     # scaled to 100\n",
    "    \n",
    "#     ret_list.append(['Testing', date_from, date_to, ret_pct])\n",
    "    \n",
    "# # ret_list\n",
    "\n",
    "\n",
    "# # -----------------------------------------------------------\n",
    "# # input\n",
    "\n",
    "# input_df = pd.DataFrame(ret_list, columns=['Type', 'From', 'To', 'ret_pct_wpbnh'])\n",
    "# output_folder = r'C:\\Users\\priva\\OneDrive - HKUST Connect\\Stock\\Data\\temp outputs'\n",
    "# output_filename_prefix = 'Whole Period BnH Pct Return'\n",
    "\n",
    "# # -----------------------------------------------------------\n",
    "\n",
    "# save_as_csv(input_df = input_df, output_folder = output_folder, output_filename_prefix = output_filename_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example codes from the internet\n",
    "# # about the use of GPU\n",
    "\n",
    "# from numba import jit, cuda\n",
    "# import numpy as np\n",
    "   \n",
    "\n",
    "# # function optimized to run on gpu \n",
    "# @jit(target_backend='cuda')                         \n",
    "# def func2(a):\n",
    "#     for i in range(10000000):\n",
    "#         a[i]+= 1\n",
    "# if __name__==\"__main__\":\n",
    "#     n = 10000000                            \n",
    "#     a = np.ones(n, dtype = np.float64)\n",
    "      \n",
    "#     start = timer()\n",
    "#     func(a)\n",
    "#     print(\"without GPU:\", timer()-start)    \n",
    "      \n",
    "#     start = timer()\n",
    "#     func2(a)\n",
    "#     print(\"with GPU:\", timer()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get % return for each testing and training period if\n",
    "##### << the given strategy is used >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# debug here 2022-10-31\n",
    "# init\n",
    "results = dict()\n",
    "\n",
    "# loop through different intervals for training and testing\n",
    "\n",
    "for p in tqdm(range(len(periods)-1, 0-1, -1), token=token, chat_id=chat_id):    # doing in reversed order\n",
    "# for p in tqdm(range(0,len(periods)), token=token, chat_id=chat_id):             # doing in order\n",
    "    \n",
    "    # send a telegram message\n",
    "    send_to_telegram(message = f'Overall Period: {periods[p]} now ({dt.datetime.now()})', token=token, chat_id=chat_id)\n",
    "    \n",
    "    # get rows for training and testing\n",
    "    rows_train = periods[p][0][0], periods[p][0][0] + int(period_toview*train_pct)\n",
    "    rows_test = rows_train[-1] + 1, periods[p][1][0]\n",
    "\n",
    "    print('\\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "    print(p)\n",
    "    print(f'Overall Period: {periods[p]}')\n",
    "    print('\\n~~~ Training : from {} to {}~~~\\n'.format(df.loc[rows_train[0], 'Date'], df.loc[rows_train[1], 'Date']))\n",
    "    \n",
    "#     # separate into df_train and df_test\n",
    "#     # here 2022-11-11 1156\n",
    "#     # consider extra prev data to generate values of KAMA-Mean in the beginning days so as to prevent NaN in these days\n",
    "    \n",
    "#     assert rows_train[0] - extra_len_init >= df.index[0], \\\n",
    "#     'Insufficient prior time series data for extra_len_init. {} more is needed.'.format(df.index[0] - rows_train[0] + extra_len_init)\n",
    "    \n",
    "#     df_summary = df.loc[rows_train[0]: rows_test[1], ['Date', 'Close', 'Close_ln']].copy()\n",
    "#     df_train = df_summary.loc[rows_train[0]-extra_len_init : rows_train[1], ]\n",
    "#     df_test = df_summary.loc[rows_test[0]-extra_len_init : rows_test[1], ]\n",
    "    \n",
    "    \n",
    "    df_summary = df.loc[rows_train[0]: rows_test[1], ['Date', 'Close', 'Close_ln']].copy()\n",
    "    df_train = df_summary.loc[rows_train[0]:rows_train[1],]\n",
    "    df_test = df_summary.loc[rows_test[0]:rows_test[1],]\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # Training set\n",
    "    # optimizate param using the df_train\n",
    "    start_time = dt.datetime.now()\n",
    "    \n",
    "    df_temp = df_train.copy(); optim_results = optimize.dual_annealing(objective_func, bounds = bounds, maxiter = maxiter, seed = seed)\n",
    "    end_time = dt.datetime.now()\n",
    "    runtime = end_time - start_time\n",
    "    optim_results['x'] = list(optim_results['x'])    # for saving in json format\n",
    "    print('Obj Func Ret: {}'.format(optim_results['fun']))\n",
    "\n",
    "    # save results to a variable\n",
    "    date_from = df_train.loc[rows_train[0], 'Date']\n",
    "    date_to = df_train.loc[rows_train[1], 'Date']\n",
    "    data_type = 'Training'\n",
    "    result_entryname_train = '{}_{}_{}_{}'.format(optim_model,data_type, date_from, date_to)\n",
    "    \n",
    "#     results[result_entryname_train] = {\n",
    "#         'Type': data_type, \n",
    "#         'From': str(df_train.loc[rows_train[0], 'Date']), \n",
    "#         'To': str(df_train.loc[rows_train[1], 'Date']),\n",
    "#         'Maxiter': maxiter,\n",
    "#         'Bounds': bounds,\n",
    "#         'Result': optim_results,\n",
    "#         'Runtime': str(runtime), \n",
    "#         'Runtime Per Iter': str(runtime/maxiter)}\n",
    "\n",
    "    results[result_entryname_train] = {\n",
    "        'Strategy': strat_name,\n",
    "        'Type': data_type, \n",
    "        'From': str(df_train.loc[rows_train[0], 'Date']), \n",
    "        'To': str(df_train.loc[rows_train[1], 'Date']),\n",
    "        'Maxiter': maxiter,\n",
    "        'Bounds': bounds,\n",
    "        'Result': optim_results,\n",
    "        'Runtime': str(runtime), \n",
    "        'Runtime Per Iter': str(runtime/maxiter),\n",
    "        'TXN Summary': txn_summary, \n",
    "        'TXN log': txn_df.to_dict()}\n",
    "\n",
    "    print(f'\\n{data_type} Completed !\\n')\n",
    "    print('Runtime: {}\\n'.format(results[result_entryname_train]['Runtime']))\n",
    "    \n",
    "    # save as json\n",
    "    \n",
    "    save_as_json(inp_dict = results[result_entryname_train], \n",
    "             output_folder = output_folder, \n",
    "             indent = 4, \n",
    "             output_filename_prefix = '{} Results_{}'.format(strat_name, result_entryname_train))\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # Testing set\n",
    "    # get param for the obj func for the testing set\n",
    "    result_touse = result_entryname_train\n",
    "    param_test = results[result_touse]['Result']['x']\n",
    "\n",
    "    # get result using the param retrieved\n",
    "    start_time = dt.datetime.now()\n",
    "    df_temp = df_test.copy()\n",
    "    obj_func_ret = objective_func(param_test)\n",
    "    end_time = dt.datetime.now()\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    print('Obj Func Ret: {}'.format(obj_func_ret))\n",
    "    \n",
    "    # save results to a variable\n",
    "    date_from = df_test.loc[rows_test[0], 'Date']\n",
    "    date_to = df_test.loc[rows_test[1], 'Date']\n",
    "    data_type = 'Testing'\n",
    "    result_entryname_test = '{}_{}_{}_{}'.format(optim_model,data_type, date_from, date_to)\n",
    "\n",
    "    results[result_entryname_test] = {\n",
    "        'Strategy': strat_name,\n",
    "        'Type': data_type, \n",
    "        'From': str(df_train.loc[rows_train[0], 'Date']), \n",
    "        'To': str(df_train.loc[rows_train[1], 'Date']),\n",
    "        'Maxiter': maxiter,\n",
    "        'x': param_test,\n",
    "        'Obj Func Ret': obj_func_ret,\n",
    "        'Runtime': str(runtime), \n",
    "        'Runtime Per Iter': str(runtime/maxiter),\n",
    "        'TXN Summary': txn_summary, \n",
    "        'TXN log': txn_df.to_dict()}\n",
    "\n",
    "    print(f'\\n{data_type} Completed !\\n')\n",
    "    print('Runtime: {}\\n'.format(results[result_entryname_test]['Runtime']))\n",
    "    \n",
    "    # save as json\n",
    "    save_as_json(inp_dict = results[result_entryname_test], \n",
    "             output_folder = output_folder, \n",
    "             indent = 4, \n",
    "             output_filename_prefix = '{} Results_{}'.format(strat_name, result_entryname_test))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_json(inp_dict = results, \n",
    "             output_folder = output_folder, \n",
    "             indent = 4, \n",
    "             output_filename_prefix = f'{strat_name} Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_to_telegram(message = f'''\n",
    "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "Execution completed.\n",
    "All results have been saved to {output_folder}.\n",
    "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "''', \n",
    "                 token=token, \n",
    "                 chat_id=chat_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temp\n",
    "\n",
    "Just for correction and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_test = pd.read_csv(r'C:\\Users\\priva\\Downloads\\2022-11-06 0222 (PlanetEdu) (Combined)\\TBC\\summary\\KAMA with KAMA-Mean Results_Test_20221110-1702-44.csv')\n",
    "# summary_test = summary_test.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_train = pd.read_csv(r'C:\\Users\\priva\\Downloads\\2022-11-06 0222 (PlanetEdu) (Combined)\\TBC\\summary\\KAMA with KAMA-Mean Results_Train_20221110-1711-6.csv')\n",
    "# summary_train = summary_train.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for the test set\n",
    "# from ast import literal_eval\n",
    "\n",
    "# for i in range(len(summary_test)):\n",
    "#     rows_toview = \\\n",
    "#     df[df['Date']==summary_test.loc[i, 'From']].index[0], \\\n",
    "#     df[df['Date']==summary_test.loc[i, 'To']].index[0]\n",
    "    \n",
    "#     df_temp = df.loc[rows_toview[0]:rows_toview[1], ['Date', 'Close', 'Close_ln']].copy()\n",
    "    \n",
    "#     param_test = literal_eval(summary_test.loc[i, 'x'])\n",
    "#     obj_func_ret = objective_func(param_test)\n",
    "    \n",
    "#     summary_test.loc[i, 'bnh_pct'] = txn_summary['bnh_pct']\n",
    "#     summary_test.loc[i, 'profit_net_pct'] = txn_summary['profit_net_pct']\n",
    "#     summary_test.loc[i, 'win_count'] = txn_summary['win_count']\n",
    "#     summary_test.loc[i, 'loss_count'] = txn_summary['loss_count']\n",
    "    \n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summary_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_as_csv(input_df = summary_test, \n",
    "#             output_folder = output_folder, \n",
    "#             output_filename_prefix = r'KAMA with KAMA-Mean Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # For debugging and testing\n",
    "# test = pd.DataFrame({'Date': df_summary.loc[df_summary.index[0:200], 'Date'], \n",
    "#                      'Close': [i for i in range(100)] + [100-i for i in range(100)]})\n",
    "# # test = add_dc( df = test, dc_source = 'Close', dc_len = 75, bound = 'upper')\n",
    "# # test = add_dc( df = test, dc_source = 'Close', dc_len = 30, bound = 'lower')\n",
    "# # test\n",
    "\n",
    "# # =====================================================\n",
    "# df_temp = test.copy()\n",
    "# n_up_interval, n_dn_interval = 5, 5\n",
    "# objective_func([75/5,\n",
    "#                 30/5,\n",
    "#                 0,\n",
    "#                 0])\n",
    "\n",
    "# txn_df\n",
    "# # =====================================================\n",
    "# # For debugging and testing\n",
    "# df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp['test'] = list(actions)\n",
    "# df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug here 2022-11-13 1011 (WIP)\n",
    "print(param_test)\n",
    "df_temp = df_test.copy()\n",
    "objective_func(param_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view plots of bounds with the close price and action points\n",
    "\n",
    "i = df_temp.index[0]\n",
    "ub_col = df_temp.columns[3]\n",
    "lb_col = df_temp.columns[4]\n",
    "\n",
    "print(df_temp.loc[i, 'Date'])\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "\n",
    "plt.plot(df_temp.loc[i:i+500, 'Close'], linestyle = 'dotted')\n",
    "# plt.plot(df_temp.loc[i:i+500, [ub_col, lb_col]], label = [ub_col, lb_col])\n",
    "\n",
    "df_temp['action_price'] = df_temp['actions'] * df_temp['Close']\n",
    "buys = df_temp.loc[i:i+500+1, 'action_price'][df_temp['action_price'] > 0]\n",
    "sells = -df_temp.loc[i:i+500+1, 'action_price'][df_temp['action_price'] < 0]\n",
    "plt.scatter(x = buys.index, y = buys, color = 'green', label = 'long')\n",
    "plt.scatter(x = sells.index, y = sells, color = 'red', label = 'short')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.plot(df_temp.loc[i:i+500, 'Close_ln'], linestyle = 'dotted')\n",
    "plt.plot(df_temp.loc[i:i+500, [ub_col, lb_col]], label = [ub_col, lb_col])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# txn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txn_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Results from a JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "  \n",
    "# Opening JSON file\n",
    "file_path = r'C:\\Users\\priva\\OneDrive - HKUST Connect\\Stock\\Data\\temp outputs\\2022-11-06 0200 (PlanetEdu)\\KAMA with KAMA-Mean Results_20221107-1721-35.json'\n",
    "f = open(file_path)\n",
    "  \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data_json = json.load(f)\n",
    "  \n",
    "# Iterating through the json\n",
    "# list\n",
    "for i in data_json:\n",
    "    print(i)\n",
    "  \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for Each Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_titles = list(results)\n",
    "# results_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inputs\n",
    "print(f'''{strat_name} \n",
    "{output_folder}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in results_titles:\n",
    "    \n",
    "    # get params for bt\n",
    "    try:\n",
    "        params = results[t]['Result']['x']\n",
    "    except:\n",
    "        params = results[t]['x']\n",
    "        \n",
    "    # get data for bt\n",
    "    date_from, date_to = t.split('_')[-2:]\n",
    "    rows_toview = df[(df['Date'] == date_from)].index[0], df[(df['Date'] == date_to)].index[0]\n",
    "    df_temp = df.loc[rows_toview[0]:rows_toview[1], ['Date', 'Close', 'Close_ln']].copy()\n",
    "    \n",
    "    # run objective_func for bt\n",
    "    objective_func(params)\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------\n",
    "    # get points of actions for plotting\n",
    "    \n",
    "    buy_markers = []\n",
    "    sell_markers = []\n",
    "\n",
    "    for i in range(df_bt.shape[0]):\n",
    "        if df_bt.loc[df_bt.index[i], 'Action Completed'] == 1:\n",
    "            buy_markers.append(df_bt.loc[df_bt.index[i], 'Close_ln'])\n",
    "            sell_markers.append(None)\n",
    "\n",
    "        elif df_bt.loc[i, 'Action Completed'] == -1:\n",
    "            buy_markers.append(None)\n",
    "            sell_markers.append(df_bt.loc[df_bt.index[i], 'Close_ln'])\n",
    "\n",
    "        else:\n",
    "            buy_markers.append(None)\n",
    "            sell_markers.append(None)\n",
    "\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------\n",
    "    # plots of action points\n",
    "    plt.figure(figsize = (20,10))\n",
    "    \n",
    "    plt.plot(df_bt.iloc[:,3], ':', color = 'blue', label = df_bt.columns[3])    # plot of Close_ln\n",
    "    plt.plot(df_bt.iloc[:,4], color = 'c', label = df_bt.columns[4])    # plot of KAMA\n",
    "    plt.plot(df_bt.iloc[:,5], color = 'brown', label = df_bt.columns[5])    # plot of KAMA-Mean\n",
    "\n",
    "    plt.scatter(x = df_bt.index, y = buy_markers, color = 'green', label = \"Buy\")\n",
    "    plt.scatter(x = df_bt.index, y = sell_markers, color = 'red', label = \"Sell\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title('''{}\n",
    "    profit_net_pct = {} ; win_count = {} ; bnh_pct = {}\n",
    "    '''.format(t, \n",
    "               round(txn_summary['profit_net_pct'],3) if not txn_summary['profit_net_pct']==None else None, \n",
    "               txn_summary['win_count'], \n",
    "               round(txn_summary['bnh_pct'],3) if not txn_summary['bnh_pct']==None else None\n",
    "              )\n",
    "             )\n",
    "    \n",
    "    img_filename = f'Graph_{strat_name} Results_{t}.png'\n",
    "    plt.savefig(output_folder + '\\\\' + img_filename, dpi = 1200)\n",
    "    print(t)\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bt.iloc[:,3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df_temp.iloc[:, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------------------------------------------------------------------------------------\n",
    "# plt.figure(figsize = (12,5))\n",
    "# plt.plot(df_bt['Equity']/df_bt.loc[0, 'Equity'])\n",
    "# plt.title('Equity Curve (Normalized) | Period: from {} to {}'.format(df_temp.loc[df_temp.index[0], 'Date'], df_temp.loc[df_temp.index[-1], 'Date']))\n",
    "# print(results['DA'])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
